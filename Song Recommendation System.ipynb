{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a song reccomendation system\n",
    "#the datasets which we are going are:Million Songs Dataset\n",
    "#Our Million Songs Dataset contains of two files: triplet_file and metadata_file. \n",
    "#The triplet_file contains user_id, song_id and listen time. \n",
    "#The metadata_file contains song_id, title, release_by and artist_name.\n",
    "\n",
    "triplets_file = 'https://static.turi.com/datasets/millionsong/10000.txt'\n",
    "songs_metadata_file = 'https://static.turi.com/datasets/millionsong/song_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df_1 = pd.read_table(triplets_file,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df_1.columns = ['user_id', 'song_id', 'listen_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df_2 =  pd.read_csv(songs_metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df=pd.merge(song_df_1, song_df_2.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_grouped = song_df.groupby(['title','song_id','artist_name']).agg({'listen_count': 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum = song_grouped['listen_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_grouped['percentage']  = song_grouped['listen_count'].div(grouped_sum)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_grouped.sort_values(['listen_count', 'title'], ascending = [0,1])\n",
    "#song_grouped.sort_values(by='listen_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = song_df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = song_df['song_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(song_df, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "class popularity_recommender_py():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.popularity_recommendations = None\n",
    "        \n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "        train_data_grouped = train_data.groupby([self.item_id]).agg({self.user_id: 'count'}).reset_index()\n",
    "        train_data_grouped.rename(columns = {'user_id': 'score'},inplace=True)\n",
    "    \n",
    "        train_data_sort = train_data_grouped.sort_values(['score', self.item_id], ascending = [0,1])\n",
    "        train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n",
    "        \n",
    "        self.popularity_recommendations = train_data_sort.head(10)\n",
    "\n",
    "    def recommend(self, user_id):    \n",
    "        user_recommendations = self.popularity_recommendations\n",
    "        \n",
    "        #Add user_id column for which the recommendations are being generated\n",
    "        user_recommendations['user_id'] = user_id\n",
    "    \n",
    "        #Bring user_id column to the front\n",
    "        cols = user_recommendations.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        user_recommendations = user_recommendations[cols]\n",
    "        \n",
    "        return user_recommendations\n",
    "    \n",
    "\n",
    "#Class for Item similarity based Recommender System model\n",
    "class item_similarity_recommender_py():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.cooccurence_matrix = None\n",
    "        self.songs_dict = None\n",
    "        self.rev_songs_dict = None\n",
    "        self.item_similarity_recommendations = None\n",
    "        \n",
    "    #Get unique items (songs) corresponding to a given user\n",
    "    def get_user_items(self, user):\n",
    "        user_data = self.train_data[self.train_data[self.user_id] == user]\n",
    "        user_items = list(user_data[self.item_id].unique())\n",
    "        \n",
    "        return user_items\n",
    "        \n",
    "    #Get unique users for a given item (song)\n",
    "    def get_item_users(self, item):\n",
    "        item_data = self.train_data[self.train_data[self.item_id] == item]\n",
    "        item_users = set(item_data[self.user_id].unique())\n",
    "            \n",
    "        return item_users\n",
    "        \n",
    "    #Get unique items (songs) in the training data\n",
    "    def get_all_items_train_data(self):\n",
    "        all_items = list(self.train_data[self.item_id].unique())\n",
    "            \n",
    "        return all_items\n",
    "        \n",
    "    #Construct cooccurence matrix\n",
    "    def construct_cooccurence_matrix(self, user_songs, all_songs):\n",
    "            \n",
    "        ####################################\n",
    "        #Get users for all songs in user_songs.\n",
    "        ####################################\n",
    "        user_songs_users = []        \n",
    "        for i in range(0, len(user_songs)):\n",
    "            user_songs_users.append(self.get_item_users(user_songs[i]))\n",
    "            \n",
    "        ###############################################\n",
    "        #Initialize the item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_songs), len(all_songs))), float)\n",
    "           \n",
    "        #############################################################\n",
    "        #Calculate similarity between user songs and all unique songs\n",
    "        #in the training data\n",
    "        #############################################################\n",
    "        for i in range(0,len(all_songs)):\n",
    "            #Calculate unique listeners (users) of song (item) i\n",
    "            songs_i_data = self.train_data[self.train_data[self.item_id] == all_songs[i]]\n",
    "            users_i = set(songs_i_data[self.user_id].unique())\n",
    "            \n",
    "            for j in range(0,len(user_songs)):       \n",
    "                    \n",
    "                #Get unique listeners (users) of song (item) j\n",
    "                users_j = user_songs_users[j]\n",
    "                    \n",
    "                #Calculate intersection of listeners of songs i and j\n",
    "                users_intersection = users_i.intersection(users_j)\n",
    "                \n",
    "                #Calculate cooccurence_matrix[i,j] as Jaccard Index\n",
    "                if len(users_intersection) != 0:\n",
    "                    #Calculate union of listeners of songs i and j\n",
    "                    users_union = users_i.union(users_j)\n",
    "                    \n",
    "                    cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n",
    "                else:\n",
    "                    cooccurence_matrix[j,i] = 0\n",
    "                    \n",
    "        \n",
    "        return cooccurence_matrix\n",
    "\n",
    "    \n",
    "    #Use the cooccurence matrix to make top recommendations\n",
    "    def generate_top_recommendations(self, user, cooccurence_matrix, all_songs, user_songs):\n",
    "        print(\"Non zero values in cooccurence_matrix :%d\" % np.count_nonzero(cooccurence_matrix))\n",
    "        \n",
    "        #Calculate a weighted average of the scores in cooccurence matrix for all user songs.\n",
    "        user_sim_scores = cooccurence_matrix.sum(axis=0)/float(cooccurence_matrix.shape[0])\n",
    "        user_sim_scores = np.array(user_sim_scores)[0].tolist()\n",
    " \n",
    "        #Sort the indices of user_sim_scores based upon their value\n",
    "        #Also maintain the corresponding score\n",
    "        sort_index = sorted(((e,i) for i,e in enumerate(list(user_sim_scores))), reverse=True)\n",
    "    \n",
    "        #Create a dataframe from the following\n",
    "        columns = ['user_id', 'song', 'score', 'rank']\n",
    "        #index = np.arange(1) # array of numbers for the number of samples\n",
    "        df = pandas.DataFrame(columns=columns)\n",
    "         \n",
    "        #Fill the dataframe with top 10 item based recommendations\n",
    "        rank = 1 \n",
    "        for i in range(0,len(sort_index)):\n",
    "            if ~np.isnan(sort_index[i][0]) and all_songs[sort_index[i][1]] not in user_songs and rank <= 10:\n",
    "                df.loc[len(df)]=[user,all_songs[sort_index[i][1]],sort_index[i][0],rank]\n",
    "                rank = rank+1\n",
    "        \n",
    "        #Handle the case where there are no recommendations\n",
    "        if df.shape[0] == 0:\n",
    "            print(\"The current user has no songs for training the item similarity based recommendation model.\")\n",
    "            return -1\n",
    "        else:\n",
    "            return df\n",
    " \n",
    "    #Create the item similarity based recommender system model\n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "    #Use the item similarity based recommender system model to\n",
    "    #make recommendations\n",
    "    def recommend(self, user):\n",
    "        \n",
    "        ########################################\n",
    "        #A. Get all unique songs for this user\n",
    "        ########################################\n",
    "        user_songs = self.get_user_items(user)    \n",
    "            \n",
    "        print(\"No. of unique songs for the user: %d\" % len(user_songs))\n",
    "        \n",
    "        ######################################################\n",
    "        #B. Get all unique items (songs) in the training data\n",
    "        ######################################################\n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        ###############################################\n",
    "        #C. Construct item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "        \n",
    "        #######################################################\n",
    "        #D. Use the cooccurence matrix to make recommendations\n",
    "        #######################################################\n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "                \n",
    "        return df_recommendations\n",
    "    \n",
    "    #Get similar items to given items\n",
    "    def get_similar_items(self, item_list):\n",
    "        \n",
    "        user_songs = item_list\n",
    "        \n",
    "        ######################################################\n",
    "        #B. Get all unique items (songs) in the training data\n",
    "        ######################################################\n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        ###############################################\n",
    "        #C. Construct item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "        \n",
    "        #######################################################\n",
    "        #D. Use the cooccurence matrix to make recommendations\n",
    "        #######################################################\n",
    "        user = \"\"\n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "         \n",
    "        return df_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = popularity_recommender_py()\n",
    "pm.create(train_data, 'user_id','song_id')\n",
    "#user the popularity model to make some prediction\n",
    "print(\"Give a random user id\")\n",
    "user_id = users[6]\n",
    "pm.recommend(user_id)\n",
    "#get the used id as input\n",
    "#for that particular user_id recommend songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model = item_similarity_recommender_py()\n",
    "is_model.create(train_data, 'user_id', 'song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the songs for the user in training data\n",
    "user_id = users[5]\n",
    "user_items = is_model.get_user_items(user_id)\n",
    "#\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Training data songs for the user userid: %s:\" % user_id)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "for user_item in user_items:\n",
    "    print(user_item)\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Recommendation process going on:\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "#Recommend songs for the user using personalized model\n",
    "is_model.recommend(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model.get_similar_items(['U Smile - Justin Bieber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings!\n",
      "Greetings!\n",
      "Greetings!\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Button\n",
    "\n",
    "class MyFirstGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"A simple GUI\")\n",
    "\n",
    "        self.label = Label(master, text=\"This is our first GUI!\")\n",
    "        self.label.pack()\n",
    "\n",
    "        self.greet_button = Button(master, text=\"Greet\", command=self.greet)\n",
    "        self.greet_button.pack()\n",
    "\n",
    "        self.close_button = Button(master, text=\"Close\", command=master.quit)\n",
    "        self.close_button.pack()\n",
    "\n",
    "    def greet(self):\n",
    "        print(\"Greetings!\")\n",
    "\n",
    "root = Tk()\n",
    "my_gui = MyFirstGUI(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
